{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from readability.readability import Document\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import Tag, BeautifulSoup\n",
    "import hashlib\n",
    "import os\n",
    "from os import path\n",
    "import sh\n",
    "import multiprocessing\n",
    "import docopt\n",
    "\n",
    "\n",
    "class Extractor(object):\n",
    "    \"\"\"\n",
    "    Extract text/ images sequences from a web page's main body\n",
    "    \"\"\"\n",
    "    def __init__(self, base_url):\n",
    "        self.cur_text = ''\n",
    "        self.result = []\n",
    "        self.base_url = base_url\n",
    "\n",
    "    def get_abs_url(self, url):\n",
    "        if url.startswith('http://') or url.startswith('https://'):\n",
    "            return url\n",
    "        else:\n",
    "            return '%s/%s' % (self.base_url, url)\n",
    "\n",
    "    def recursive_extract_text_image(self, obj):\n",
    "        # reference:\n",
    "        # http://stackoverflow.com/questions/20590624/python-beautifulsoup-div-text-and-img-attributes-in-correct-order\n",
    "        for child in obj.children:\n",
    "            if isinstance(child, Tag):\n",
    "                #result.append(child.get('alt', ''))\n",
    "                self.recursive_extract_text_image(child)\n",
    "                if child.name == 'img':\n",
    "                    self.result.append(('text', self.cur_text))\n",
    "                    self.cur_text = ''\n",
    "                    self.result.append(('image',\n",
    "                                        self.get_abs_url(child['src'])\n",
    "                    ))\n",
    "            else:\n",
    "                if len(child.strip()) > 0:\n",
    "                    self.cur_text += ' ' + child.strip() + ' '\n",
    "\n",
    "    def html_to_asset_list(self, html):\n",
    "        \"\"\"\n",
    "        :param html: The html content in str\n",
    "        :return: The extracted list of text/ image sequence\n",
    "        \"\"\"\n",
    "        bs_obj = BeautifulSoup(html, 'html.parser')\n",
    "        self.result = []\n",
    "        self.cur_text = ''\n",
    "        self.recursive_extract_text_image(bs_obj)\n",
    "        self.result.append(('text', self.cur_text))\n",
    "        return self.result\n",
    "\n",
    "\n",
    "#global_pool = None\n",
    "\n",
    "class Converter(object):\n",
    "    def __init__(self, num_pools=4):\n",
    "        #global global_pool\n",
    "        #global_pool = multiprocessing.Pool(num_pools)\n",
    "        pass\n",
    "\n",
    "    def execute(self, command):\n",
    "        return os.system(command)\n",
    "\n",
    "    def execute_all(self, commands):\n",
    "        #global global_pool\n",
    "        #return global_pool.map(self.execute, commands)\n",
    "        print(commands)\n",
    "        for c in commands:\n",
    "            os.system(c)\n",
    "\n",
    "    def string2hash(self, s):\n",
    "        m = hashlib.sha256()\n",
    "        m.update(s.encode('utf-8'))\n",
    "        return m.hexdigest()[:16]\n",
    "\n",
    "    def get_audio_length(self, local_src):\n",
    "        filename = local_src + '.wav'\n",
    "        # Caveats: can only deal with < 60s audios\n",
    "        # | grep Duration | cut -f1 -d, | cut -f4 -d:\n",
    "        seconds = sh.soxi('-D', filename)\n",
    "        return seconds.strip()\n",
    "\n",
    "    def get_screen_play(self, url):\n",
    "        \"\"\"Download webpage and analyze basic sequence\n",
    "\n",
    "        :param url:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        res = requests.get(url)\n",
    "        html = res.content.decode('utf-8')\n",
    "        # Analyze basic sequence\n",
    "        readable_article = Document(html).summary()\n",
    "        base_url = path.dirname(res.request.url)\n",
    "        result = Extractor(base_url).html_to_asset_list(readable_article)\n",
    "        #print(result)\n",
    "        df_screenplay = pd.DataFrame(result, columns=['type', 'content'])\n",
    "        df_screenplay['local_src'] = df_screenplay['content'].apply(lambda x: self.string2hash(x))\n",
    "        image_selector = (df_screenplay['type'] == 'image')\n",
    "        df_screenplay.loc[image_selector, 'filename'] = df_screenplay.loc[\n",
    "            image_selector, 'content'].apply(lambda x: path.basename(x))\n",
    "        df_screenplay.loc[image_selector, 'extname'] = df_screenplay.loc[\n",
    "            image_selector, 'filename'].apply(lambda x: path.splitext(x)[1])\n",
    "        df_screenplay = df_screenplay.fillna('')\n",
    "        df_screenplay['download_name'] = df_screenplay['local_src'] + df_screenplay['extname']\n",
    "        df_screenplay['converted_name'] = df_screenplay['local_src'] + '.png'\n",
    "\n",
    "        self.df_screenplay = df_screenplay\n",
    "        return df_screenplay\n",
    "\n",
    "    def get_png_images(self):\n",
    "        \"\"\"Download images and convert to .png\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        commands = []\n",
    "        for (i, r) in self.df_screenplay.iterrows():\n",
    "            if r['type'] == 'image':\n",
    "                commands.append('wget {content} -O {download_name}'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "        commands = []\n",
    "        for (i, r) in self.df_screenplay.iterrows():\n",
    "            if r['type'] == 'image':\n",
    "                commands.append('convert {download_name} {converted_name}'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "\n",
    "    def text_to_speech(self, rate, voice):\n",
    "        \"\"\" Generate audio via say (m4a) and convert to (wav)\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        commands = []\n",
    "        for (i, r) in self.df_screenplay.iterrows():\n",
    "            if r['type'] == 'text':\n",
    "                #commands.append('say --output-file={local_src}.m4a --voice=daniel --rate=220 --progress --file-format=m4af \"{content}\"'.format(**r))\n",
    "                #commands.append('say --output-file={local_src}.m4a -v Ting-Ting --rate=300 --progress --file-format=m4af \"{content}\"'.format(**r))\n",
    "                commands.append('say --output-file={local_src}.m4a -v {voice} --rate={rate} --progress --file-format=m4af \"{content}\"'.format(rate=rate, voice=voice, **r))\n",
    "        self.execute_all(commands)\n",
    "        # Convert to .wav\n",
    "        commands = []\n",
    "        for (i, r) in self.df_screenplay.iterrows():\n",
    "            if r['type'] == 'text':\n",
    "                commands.append('avconv -i {local_src}.m4a -y {local_src}.wav'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "        # Analyze audio duration\n",
    "        text_selector = (self.df_screenplay['type'] == 'text')\n",
    "        self.df_screenplay.loc[text_selector, 'duration'] = self.df_screenplay.loc[text_selector, 'local_src'].apply(self.get_audio_length)\n",
    "\n",
    "    def organise_scenes(self):\n",
    "        \"\"\" Organise scenes\n",
    "        From:\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        scenes = []\n",
    "        df_sp_orged = self.df_screenplay.reset_index()\n",
    "        # Group the sequence\n",
    "        df_sp_orged['group'] = df_sp_orged['index'].apply(lambda x: int((x + 1) / 2))\n",
    "        for (gname, group) in df_sp_orged.groupby('group'):\n",
    "            if len(group[group['type'] == 'image']) == 0:\n",
    "                fn_image = 'default-image.png'\n",
    "            else:\n",
    "                fn_image = group[group['type'] == 'image']['converted_name'].values[0]\n",
    "\n",
    "            if len(group[group['type'] == 'text']) == 0:\n",
    "                duration = 1.53\n",
    "                fn_audio = 'default-audio.mp4'\n",
    "            else:\n",
    "                duration = group[group['type'] == 'text']['duration'].values[0]\n",
    "                fn_audio = group[group['type'] == 'text']['local_src'].values[0] + '.m4a'\n",
    "            scenes.append(('%04d' % gname, fn_image, duration, fn_audio))\n",
    "        df_scenes = pd.DataFrame(scenes, columns=['group', 'fn_image', 'duration', 'fn_audio'])\n",
    "\n",
    "        df_scenes['fn_video_only'] = 'group' + df_scenes['group'] + '.mp4'\n",
    "        df_scenes['fn_video'] = 'group' + df_scenes['group'] + '-a.mp4'\n",
    "        # Following was used to solve non integer fps problem the conflicts with stanrdard\n",
    "        # Now we already use output parameter to work around.\n",
    "        #df_scenes['duration'] = df_scenes['duration'].apply(lambda x: int(np.ceil(float(x))))\n",
    "        df_scenes['fn_image_resized'] = 'resized-' + df_scenes['fn_image']\n",
    "        df_scenes['fn_audio_only'] = 'group' + df_scenes['group'] + '-audio.m4a'\n",
    "        # To avoid too short clips\n",
    "        df_scenes = df_scenes[df_scenes['duration'].apply(lambda x: float(x) > 0.1)]\n",
    "\n",
    "        self.df_sp_orged = df_sp_orged\n",
    "        self.df_scenes = df_scenes\n",
    "\n",
    "    def prepare_default_assets(self):\n",
    "        os.system('cp -f default/* .')\n",
    "\n",
    "    def images_to_videos(self, screen_size):\n",
    "        commands = []\n",
    "        for (i, r) in self.df_scenes.iterrows():\n",
    "            commands.append('convert {fn_image} -resize {screen_size} {fn_image_resized}'.format(screen_size=screen_size, **r))\n",
    "        self.execute_all(commands)\n",
    "        commands = []\n",
    "        for (i, r) in self.df_scenes.iterrows():\n",
    "            commands.append('ffmpeg -f image2 -r 1/{duration} -i {fn_image_resized} -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 {fn_video_only}'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "\n",
    "    def videos_add_audio(self):\n",
    "        commands = []\n",
    "        for (i, r) in self.df_scenes.iterrows():\n",
    "            commands.append('cp {fn_audio} {fn_audio_only}'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "        commands = []\n",
    "        for (i, r) in self.df_scenes.iterrows():\n",
    "            commands.append('ffmpeg -i {fn_video_only} -i {fn_audio} -qscale:v 1 -copyts -vcodec copy -acodec copy -y {fn_video}'.format(**r))\n",
    "            #commands.append('ffmpeg -i {fn_video_only} -i {fn_audio} -map 0:0 -map 1 -vcodec copy -acodec copy -y {fn_video}'.format(**r))\n",
    "        self.execute_all(commands)\n",
    "\n",
    "    def assemble_output(self, fn_output):\n",
    "        open('playlist.txt', 'w').write('\\n'.join(list(self.df_scenes['fn_video'].apply(lambda x: \"file '%s'\" % x))))\n",
    "        os.system('ffmpeg -f concat -i playlist.txt -c copy -y %s' % fn_output)\n",
    "\n",
    "    def convert(self, url, fn_output, rate=220, voice='Ting-Ting', screen_size='600x400!'):\n",
    "        self.get_screen_play(url)\n",
    "        self.get_png_images()\n",
    "        self.text_to_speech(rate, voice)\n",
    "        self.organise_scenes()\n",
    "        self.prepare_default_assets()\n",
    "        self.images_to_videos(screen_size)\n",
    "        self.videos_add_audio()\n",
    "        self.assemble_output(fn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://project.initiumlab.com/news2video/case1/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wget http://project.initiumlab.com/news2video/case1/1.jpg -O 5bf67d1c0729bd50.jpg', 'wget http://project.initiumlab.com/news2video/case1/2.jpg -O 3a9e810ed3b010a4.jpg', 'wget http://project.initiumlab.com/news2video/case1/3.jpg -O b30b2910be978147.jpg', 'wget http://project.initiumlab.com/news2video/case1/4.jpg -O f7c4cc87ce36317c.jpg', 'wget http://project.initiumlab.com/news2video/case1/5.jpg -O bb32e45dfe24271c.jpg', 'wget http://project.initiumlab.com/news2video/case1/6.jpg -O 9126b1c656683fc7.jpg', 'wget http://project.initiumlab.com/news2video/case1/7.jpg -O 41d9ad7a1b980e63.jpg', 'wget http://project.initiumlab.com/news2video/case1/8.jpg -O 50caf99e2383f614.jpg', 'wget http://project.initiumlab.com/news2video/case1/9.jpg -O f30c6fbc6875126a.jpg']\n",
      "['convert 5bf67d1c0729bd50.jpg 5bf67d1c0729bd50.png', 'convert 3a9e810ed3b010a4.jpg 3a9e810ed3b010a4.png', 'convert b30b2910be978147.jpg b30b2910be978147.png', 'convert f7c4cc87ce36317c.jpg f7c4cc87ce36317c.png', 'convert bb32e45dfe24271c.jpg bb32e45dfe24271c.png', 'convert 9126b1c656683fc7.jpg 9126b1c656683fc7.png', 'convert 41d9ad7a1b980e63.jpg 41d9ad7a1b980e63.png', 'convert 50caf99e2383f614.jpg 50caf99e2383f614.png', 'convert f30c6fbc6875126a.jpg f30c6fbc6875126a.png']\n",
      "['say --output-file=0b6f2772f708dd15.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" Walk: A Boring Story  I\\'m going to tell you a boring story. \"', 'say --output-file=e99d8b267c0f2b29.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the first step I move. \"', 'say --output-file=07c025cc4e45e727.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the second step I move. \"', 'say --output-file=b30a844bd7d16bd3.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the third step I move. \"', 'say --output-file=f5329785a4ee9a50.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the fourth step I move. \"', 'say --output-file=ac1257d717ef7162.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the fifth step I move. \"', 'say --output-file=7539841ff27fa2c9.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the sixth step I move. \"', 'say --output-file=bc18b83623f6c7c4.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the seventh step I move. \"', 'say --output-file=8bd9c4d8f557bc46.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the eighth step I move. \"', 'say --output-file=e446517dd3833069.m4a -v Ting-Ting --rate=220 --progress --file-format=m4af \" This is the final step I move.  Thank you for reading this story. \"']\n",
      "['avconv -i 0b6f2772f708dd15.m4a -y 0b6f2772f708dd15.wav', 'avconv -i e99d8b267c0f2b29.m4a -y e99d8b267c0f2b29.wav', 'avconv -i 07c025cc4e45e727.m4a -y 07c025cc4e45e727.wav', 'avconv -i b30a844bd7d16bd3.m4a -y b30a844bd7d16bd3.wav', 'avconv -i f5329785a4ee9a50.m4a -y f5329785a4ee9a50.wav', 'avconv -i ac1257d717ef7162.m4a -y ac1257d717ef7162.wav', 'avconv -i 7539841ff27fa2c9.m4a -y 7539841ff27fa2c9.wav', 'avconv -i bc18b83623f6c7c4.m4a -y bc18b83623f6c7c4.wav', 'avconv -i 8bd9c4d8f557bc46.m4a -y 8bd9c4d8f557bc46.wav', 'avconv -i e446517dd3833069.m4a -y e446517dd3833069.wav']\n",
      "['convert default-image.png -resize 600x400! resized-default-image.png', 'convert 5bf67d1c0729bd50.png -resize 600x400! resized-5bf67d1c0729bd50.png', 'convert 3a9e810ed3b010a4.png -resize 600x400! resized-3a9e810ed3b010a4.png', 'convert b30b2910be978147.png -resize 600x400! resized-b30b2910be978147.png', 'convert f7c4cc87ce36317c.png -resize 600x400! resized-f7c4cc87ce36317c.png', 'convert bb32e45dfe24271c.png -resize 600x400! resized-bb32e45dfe24271c.png', 'convert 9126b1c656683fc7.png -resize 600x400! resized-9126b1c656683fc7.png', 'convert 41d9ad7a1b980e63.png -resize 600x400! resized-41d9ad7a1b980e63.png', 'convert 50caf99e2383f614.png -resize 600x400! resized-50caf99e2383f614.png', 'convert f30c6fbc6875126a.png -resize 600x400! resized-f30c6fbc6875126a.png']\n",
      "['ffmpeg -f image2 -r 1/3.947392 -i resized-default-image.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0000.mp4', 'ffmpeg -f image2 -r 1/2.321995 -i resized-5bf67d1c0729bd50.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0001.mp4', 'ffmpeg -f image2 -r 1/2.414875 -i resized-3a9e810ed3b010a4.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0002.mp4', 'ffmpeg -f image2 -r 1/2.275556 -i resized-b30b2910be978147.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0003.mp4', 'ffmpeg -f image2 -r 1/2.275556 -i resized-f7c4cc87ce36317c.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0004.mp4', 'ffmpeg -f image2 -r 1/2.321995 -i resized-bb32e45dfe24271c.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0005.mp4', 'ffmpeg -f image2 -r 1/2.368435 -i resized-9126b1c656683fc7.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0006.mp4', 'ffmpeg -f image2 -r 1/2.414875 -i resized-41d9ad7a1b980e63.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0007.mp4', 'ffmpeg -f image2 -r 1/2.136236 -i resized-50caf99e2383f614.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0008.mp4', 'ffmpeg -f image2 -r 1/4.551111 -i resized-f30c6fbc6875126a.png -qscale:v 1 -copyts -vcodec mpeg4 -y -r 25 group0009.mp4']\n",
      "['cp 0b6f2772f708dd15.m4a group0000-audio.m4a', 'cp e99d8b267c0f2b29.m4a group0001-audio.m4a', 'cp 07c025cc4e45e727.m4a group0002-audio.m4a', 'cp b30a844bd7d16bd3.m4a group0003-audio.m4a', 'cp f5329785a4ee9a50.m4a group0004-audio.m4a', 'cp ac1257d717ef7162.m4a group0005-audio.m4a', 'cp 7539841ff27fa2c9.m4a group0006-audio.m4a', 'cp bc18b83623f6c7c4.m4a group0007-audio.m4a', 'cp 8bd9c4d8f557bc46.m4a group0008-audio.m4a', 'cp e446517dd3833069.m4a group0009-audio.m4a']\n",
      "['ffmpeg -i group0000.mp4 -i 0b6f2772f708dd15.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0000-a.mp4', 'ffmpeg -i group0001.mp4 -i e99d8b267c0f2b29.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0001-a.mp4', 'ffmpeg -i group0002.mp4 -i 07c025cc4e45e727.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0002-a.mp4', 'ffmpeg -i group0003.mp4 -i b30a844bd7d16bd3.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0003-a.mp4', 'ffmpeg -i group0004.mp4 -i f5329785a4ee9a50.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0004-a.mp4', 'ffmpeg -i group0005.mp4 -i ac1257d717ef7162.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0005-a.mp4', 'ffmpeg -i group0006.mp4 -i 7539841ff27fa2c9.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0006-a.mp4', 'ffmpeg -i group0007.mp4 -i bc18b83623f6c7c4.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0007-a.mp4', 'ffmpeg -i group0008.mp4 -i 8bd9c4d8f557bc46.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0008-a.mp4', 'ffmpeg -i group0009.mp4 -i e446517dd3833069.m4a -qscale:v 1 -copyts -vcodec copy -acodec copy -y group0009-a.mp4']\n"
     ]
    }
   ],
   "source": [
    "Converter().convert(url, 'out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
